version: '3'
services:
  postgres:
    build:
      context: ./docker/postgres/
      dockerfile: Dockerfile
    image: postgres
    container_name: postgres
    restart: on-failure
    networks:
      - default_net
    environment:
      - POSTGRES_USERS=airflow:airflow|test:postgres
      - POSTGRES_DATABASES=airflow:airflow|test:test
    ports:
      - 5433:5432

  # Airflow LocalExecutor
  airflow-webserver:
    build:
      context: ./docker/docker-airflow/
      dockerfile: Dockerfile
    image: airflow-spark
    container_name: airflow-webserver
    restart: on-failure
    networks:
      - default_net
    depends_on:
      - postgres
    environment:
      - LOAD_EX=n
      - EXECUTOR=Local
    volumes:
      - ./spark/app:/usr/local/spark/app
      - ./spark/resources:/usr/local/spark/resources
    ports:
      - 8080:8080
    command: webserver
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "[ -f /usr/local/airflow/airflow-webserver.pid ]"
        ]
      interval: 30s
      timeout: 30s
      retries: 3

  # Spark with 3 worker
  spark:
    image: spark
    build:
      context: ./docker/docker-spark/
      dockerfile: Dockerfile
    user: root
    hostname: spark
    restart: on-failure
    container_name: spark-master
    networks:
      - default_net
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - ./spark/app:/usr/local/spark/app
      - ./spark/resources:/usr/local/spark/resources
    ports:
      - 8181:8181
      - 7077:7077

  spark-worker-1:
    image: spark
    build:
      context: ./docker/docker-spark/
      dockerfile: Dockerfile
    user: root
    restart: on-failure
    container_name: spark-worker-1
    networks:
      - default_net
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - ./spark/app:/usr/local/spark/app
      - ./spark/resources:/usr/local/spark/resources

  # spark:
  #   image: bitnami/spark:3.2.4
  #   user: root
  #   hostname: spark
  #   restart: on-failure
  #   container_name: spark-master
  #   networks:
  #     - default_net
  #   environment:
  #     - SPARK_MODE=master
  #     - SPARK_RPC_AUTHENTICATION_ENABLED=no
  #     - SPARK_RPC_ENCRYPTION_ENABLED=no
  #     - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
  #     - SPARK_SSL_ENABLED=no
  #   volumes:
  #     - ./spark/app:/usr/local/spark/app
  #     - ./spark/resources:/usr/local/spark/resources
  #   ports:
  #     - 8181:8080
  #     - 7077:7077

  # spark-worker-1:
  #   image: bitnami/spark:3.2.4
  #   user: root
  #   restart: on-failure
  #   container_name: spark-worker-1
  #   networks:
  #     - default_net
  #   environment:
  #     - SPARK_MODE=worker
  #     - SPARK_MASTER_URL=spark://spark:7077
  #     - SPARK_WORKER_MEMORY=1G
  #     - SPARK_WORKER_CORES=1
  #     - SPARK_RPC_AUTHENTICATION_ENABLED=no
  #     - SPARK_RPC_ENCRYPTION_ENABLED=no
  #     - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
  #     - SPARK_SSL_ENABLED=no
  #   volumes:
  #     - ./spark/app:/usr/local/spark/app
  #     - ./spark/resources:/usr/local/spark/resources

  # Jupyter notebook
  jupyter-spark:
    image: jupyter/pyspark-notebook:spark-3.4.0
    restart: on-failure
    container_name: jupyter-spark
    networks:
      - default_net
    ports:
      - 8888:8888
      - 4040-4080:4040-4080
    volumes:
      - ./notebooks:/home/jovyan/work/notebooks/
      - ./spark/resources/data:/home/jovyan/work/data/
      - ./spark/resources/jars:/home/jovyan/work/jars/

networks:
  default_net:
